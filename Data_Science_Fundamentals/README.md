# Data Science Fundamentals

This module consolidates my foundational projects in Data Science, documenting my journey from data acquisition and cleaning to advanced statistical inference and model evaluation. 

As a student of **Information Technologies for Science** at **ENES Morelia, UNAM**, I apply a rigorous, bilingual (Python & R) approach to solve data-driven problems.

## Featured Projects

### 1. [Pokemon Statistical Analysis: Evolution & Multivariate Study](./R_Pokemon_Stats)
A deep dive into "Power Creep" and game balance. This project replicates and expands upon my academic research for the Descriptive and Inferential Statistics course.
* **Key Skills:** Hypothesis Testing (Normality, Homoscedasticity), OLS Regression, Residual Diagnostics.
* **Bilingual Implementation:** Comparison of statistical outputs between `R (Tidyverse)` and `Python (Statsmodels)`.

### 2. [Titanic: Data Wrangling & EDA](./Titanic_Wrangling/notebooks/analysis_and_cleaning.ipynb)
* **Context:** A classic dataset analysis focusing on data quality and survival factors.
* **Key Achievements:** Extensive data cleaning (imputation of 'Age' and 'Cabin') and visualization of survival correlations.

### 3. [Web Scraping: Books Market Analysis](./Books_Scraping/notebooks/books_market_analysis.ipynb)
* **Context:** Automating the extraction of market data to demonstrate ETL capabilities.
* **Key Achievements:** Built a scraper using **BeautifulSoup** to transform unstructured HTML into clean DataFrames.

### 4. [Cross-Validation & Advanced Metrics](./Model_Evaluation/notebooks/model_evaluation.ipynb)
* **Context:** Evaluating model robustness using K-Fold Cross-Validation on the CIA Countries dataset.

---

## Global Tech Stack
* **Languages:** Python 3.x & R 4.x (Bilingual Statistical Analysis).
* **Data Science & Modeling:** Pandas, NumPy, SciPy, Statsmodels, Scikit-Learn.
* **Statistical Rigor (R):** Tidyverse, Car, Nortest, Lmtest.
* **Visualization:** Matplotlib, Seaborn (Python) and Ggplot2 (R).
* **Data Acquisition:** BeautifulSoup4, Requests (ETL & Web Scraping).
* **IDE & Environment:** Visual Studio Code, Jupyter Ecosystem & Ubuntu Linux.

## Learning Path
1. **Data Acquisition:** Web scraping and automated data collection.
2. **Data Foundations:** Wrangling, cleaning, and feature engineering. 
3. **Statistical Inference:** Testing significance and predictive modeling.
4. **Current Milestone:** [Deep Learning & Neural Networks] (In Progress).

---
*Developed as part of my Applied CS Data Journey | ENES Morelia, UNAM.*